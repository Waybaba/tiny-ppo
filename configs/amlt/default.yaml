description: AMLT

target:
  service: singularity
  name: msrresrchvc    # more GPUs 

environment:
  image: waybaba/rl:v2
  username: waybaba
  setup:
    - echo "setup start..."
    - export UPRJDIR=/mnt/default/
    - export UDATADIR=/mnt/storage/data
    - export UOUTDIR=/mnt/storage/output
    - mkdir -p /mnt/storage/output /mnt/storage/data
    - echo "setup finished!"


code:
  local_dir: $CONFIG_DIR/../../

storage:
  input:
    storage_account_name: resrchvc4data
    container_name: v-wangwei1
    mount_dir: /mnt/storage
    local_dir: /home/v-wangwei1/storage

# search:
#   job_template:
#     name: delay_{experiment_name:s}_{auto:5s}
#     command:
#     - python agent/sac.py
#       train_collector.buffer.size={train_collector_buffer_size}
#       policy._target_=tianshou.policy.SACPolicy
#       env.delay={env_delay}
#       seed={seed}
#       tags=["delay_amlt_test_2"]
#   type: grid
#   max_trials: 10000
#   params:
#     - name: train_collector_buffer_size
#       values: [1000000,100000,10000]
#     - name: env_delay
#       values: [1,4,8,16,2,32,0]
#     - name: seed
#       values: [0,1,2,3,4]


# search:
#   job_template:
#     name: delay_amlt_rnn_and_normal{experiment_name:s}_{auto:5s}
#     command:
#     - python agent/sac.py
#       train_collector.buffer.size={train_collector_buffer_size}
#       policy._target_=agent.sac.AsyncACSACPolicy
#       env.delay={env_delay}
#       net={net}
#       net@net_c1={net}
#       seed={seed}
#       tags=["delay_amlt_rnn_and_normal"]
#   type: grid
#   max_trials: 10000
#   params:
#     - name: train_collector_buffer_size
#       values: [1000000,100000,10000]
#     - name: env_delay
#       values: [1,4,8,16,2,32,0]
#     - name: seed
#       values: [0,1,2,3,4]
#     - name: net
#       values: [default,rnn]

# # mine_with_params_as_donqi
# search:
#   job_template:
#     name: delay_amlt_rnn_and_normal{experiment_name:s}_{auto:5s}
#     command:
#     - python agent/sac.py
#       train_collector.buffer.size={train_collector_buffer_size}
#       policy._target_=agent.sac.AsyncACSACPolicy
#       env.delay={env_delay}
#       net={net}
#       net@net_c1={net}
#       seed={seed}
#       tags=["mine_with_params_as_donqi"]
#   type: grid
#   max_trials: 10000
#   params:
#     - name: train_collector_buffer_size
#       values: [1000000]
#     - name: env_delay
#       values: [1,4,8,16,2,32,0]
#     - name: seed
#       values: [0,1,2,3,4]
#     - name: net
#       values: [default]


# # mine_with_params_as_donqi_plus_net
# search:
#   job_template:
#     name: delay_amlt_rnn_and_normal{experiment_name:s}_{auto:5s}
#     command:
#     - python agent/sac.py
#       train_collector.buffer.size={train_collector_buffer_size}
#       policy._target_=agent.sac.AsyncACSACPolicy
#       env.delay={env_delay}
#       net={net}
#       net@net_c1={net}
#       seed={seed}
#       tags=["mine_with_params_as_donqi_plus_net"]
#   type: grid
#   max_trials: 10000
#   params:
#     - name: train_collector_buffer_size
#       values: [1000000]
#     - name: env_delay
#       values: [1,4,8,16,2,32,0]
#     - name: seed
#       values: [0,1,2,3,4]
#     - name: net
#       values: [default]


# search:
#   job_template:
#     name: delay_amlt_rnn_and_normal{experiment_name:s}_{auto:5s}
#     command:
#     - python agent/sac.py
#       train_collector.buffer.size={train_collector_buffer_size}
#       policy._target_=agent.sac.AsyncACSACPolicy
#       env.delay={env_delay}
#       net={net}
#       net@net_c1={net}
#       seed={seed}
#       tags=["mine_with_params_as_donqi_plus_net_trainable_alpha_lr_change"]
#   type: grid
#   max_trials: 10000
#   params:
#     - name: train_collector_buffer_size
#       values: [1000000]
#     - name: env_delay
#       values: [1,4,8,16,2,32,0]
#     - name: seed
#       values: [0,1,2,3,4]
#     - name: net
#       values: [default]

# # mine_with_params_as_donqi_plus_net_trainable_alpha_lr_change_reg_7
# search:
#   job_template:
#     name: delay_amlt_rnn_and_normal{experiment_name:s}_{auto:5s}
#     command:
#     - python agent/sac.py
#       policy.critic_use_oracle_obs={critic_use_oracle_obs}
#       collector.train_collector.buffer.size={train_collector_buffer_size}
#       policy._target_=agent.sac.AsyncACSACPolicy
#       env.delay={env_delay}
#       env.name={env_name}
#       net={net}
#       net@net_c1={net}
#       seed={seed}
#       tags=["START_complex"]
#   type: grid
#   max_trials: 10000
#   params:
#     - name: train_collector_buffer_size
#       values: [1000000]
#     - name: env_delay
#       values: [1,4,8,16,2,32,0]
#     - name: seed
#       values: [0,1,2,3,4]
#     - name: critic_use_oracle_obs
#       values: [true]
#     - name: net
#       values: [default]
#     - name: env_name
#       # values: [HalfCheetah-v4]
#       values: [Ant-v4,Hopper-v4,Walker2d-v4]

search:
  job_template:
    name: delay_amlt_rnn_and_normal{experiment_name:s}_{auto:5s}
    command:
    - python src/entry.py
      experiment={experiment}
      env.name={env_name}
      actor.mlp_hidden_sizes={actor_mlp_hidden_sizes}
      actor.rnn_layer_num={actor_rnn_layer_num}
      actor.rnn_hidden_layer_size={actor_rnn_hidden_layer_size}
      env.delay={env_delay}
      seed={seed}
      tags=[{tag}]
      global_cfg.historical_act.type={historical_act_type}
      global_cfg.historical_act.num={historical_act_num}
  type: grid
  max_trials: 10000
  params:
    - name: env_delay
      # values: [0,1,2,4,8,16,32]
      values: [0,2,8,16]
    - name: seed
      values: [0,1,2,3,4]
    - name: env_name
      values: [HalfCheetah-v4]
      # values: [Ant-v4,Hopper-v4,Walker2d-v4,HalfCheetah-v4]
    - name: experiment
      values: [sac_rnn]
    - name: tag
      values: ["sac_rnn_cat_act_mlp_deeper_NewCode_add_zero"]
    - name: historical_act_type
      values: [cat_mlp]
    - name: historical_act_num
      values: [0,1,2,4,8]
    - name: actor_mlp_hidden_sizes
      values: ["[256,256]","[256,256,256]"]
    - name: actor_rnn_layer_num
      values: [0]
    - name: actor_rnn_hidden_layer_size
      values: [256]

    